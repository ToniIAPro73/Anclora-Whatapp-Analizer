const fetch = require('node-fetch');
const logger = require('../utils/logger');

const OLLAMA_HOST = process.env.OLLAMA_HOST || 'http://localhost:11434';
const OLLAMA_MODEL = process.env.OLLAMA_MODEL;

/**
 * Analiza contenido usando Ollama
 * @param {string} content - Contenido a analizar
 * @param {string} url - URL del contenido
 * @param {string} platform - Plataforma de origen
 * @returns {Promise<Object>} An√°lisis estructurado
 */
async function analyzeContent(content, url, platform) {
    const startTime = Date.now();
    
    // Trunca contenido si es muy largo (optimizaci√≥n para inferencia)
    const truncatedContent = content.length > 8000 
        ? content.substring(0, 8000) + '...' 
        : content;
    
    const systemPrompt = `Eres un analista experto en contenido de inteligencia artificial, tecnolog√≠a y Real Estate.

CONTEXTO DEL USUARIO:
- Trabaja en consultor√≠a de IA generativa y Real Estate
- Desarrolla productos bajo la marca Anclora (Press, Nexus, Kairon, etc)
- Promociona complejo residencial Playa Viva para mercados espa√±ol y latinoamericano
- Inter√©s especial en: AI Agents, RAG, automatizaci√≥n, LLMs, desarrollo de aplicaciones

TAREA:
Analiza el siguiente contenido de ${platform} y genera un resumen estructurado en espa√±ol.

URL: ${url}

CONTENIDO:
${truncatedContent}

RESPONDE √öNICAMENTE CON UN OBJETO JSON V√ÅLIDO (sin markdown, sin explicaciones):
{
  "resumen_ejecutivo": "Resumen conciso en m√°ximo 3 frases",
  "temas_principales": ["tag1", "tag2", "tag3"],
  "insights_clave": [
    "Insight 1: Punto espec√≠fico y accionable",
    "Insight 2: Punto espec√≠fico y accionable", 
    "Insight 3: Punto espec√≠fico y accionable"
  ],
  "relevancia": 4,
  "categoria": "AI Agents",
  "tipo_contenido": "Tutorial"
}

CATEGOR√çAS V√ÅLIDAS (selecciona UNA):
- "AI Agents" (sistemas ag√©nticos, LangChain, CrewAI, AutoGPT)
- "LLMs" (modelos de lenguaje, fine-tuning, prompting)
- "MLOps" (deployment, monitoring, infraestructura ML)
- "Computer Vision" (visi√≥n por computador, detecci√≥n objetos)
- "NLP" (procesamiento lenguaje natural, embeddings)
- "RAG" (Retrieval Augmented Generation, vectores, b√∫squeda)
- "Automation" (automatizaci√≥n, RPA, workflows)
- "Real Estate Tech" (proptech, CRM inmobiliario, marketing)
- "Desarrollo Software" (frameworks, herramientas, metodolog√≠as)
- "Data Science" (an√°lisis datos, visualizaci√≥n, estad√≠stica)
- "Otro" (si no encaja en anteriores)

TIPOS DE CONTENIDO V√ÅLIDOS (selecciona UNO):
- "Tutorial" (gu√≠a paso a paso, how-to)
- "Noticia" (anuncio, novedad, actualizaci√≥n)
- "Opini√≥n" (art√≠culo de opini√≥n, an√°lisis personal)
- "Investigaci√≥n" (paper, estudio, whitepaper)
- "Herramienta" (nuevo tool, librer√≠a, framework)
- "Case Study" (caso de uso, implementaci√≥n real)
- "Debate" (discusi√≥n, controversia, m√∫ltiples perspectivas)

CRITERIOS DE RELEVANCIA (1-5):
5 = Directamente aplicable a proyectos actuales (Anclora, Playa Viva)
4 = T√©cnica/herramienta muy √∫til para el trabajo diario
3 = Conocimiento general valioso en IA/tech
2 = Tangencialmente relacionado con √°reas de inter√©s
1 = No relevante para el contexto profesional

IMPORTANTE:
- Solo JSON, sin markdown ni bloques de c√≥digo
- Insights deben ser espec√≠ficos y accionables
- Tags concisos (1-3 palabras m√°ximo)
- Prioriza calidad sobre cantidad`;

    try {
        logger.info('ü§ñ Llamando a Ollama...');
        
        const response = await fetch(`${OLLAMA_HOST}/api/generate`, {
            method: 'POST',
            headers: { 'Content-Type': 'application/json' },
            body: JSON.stringify({
                model: OLLAMA_MODEL,
                prompt: systemPrompt,
                stream: false,
                format: 'json',
                options: {
                    temperature: 0.3,
                    top_p: 0.9,
                    top_k: 40,
                    num_ctx: 4096,
                    num_gpu: 1,  // Fuerza uso de GPU
                    num_thread: 8
                }
            })
        });

        if (!response.ok) {
            throw new Error(`Ollama HTTP error: ${response.status} ${response.statusText}`);
        }

        const data = await response.json();
        const inferenceTime = ((Date.now() - startTime) / 1000).toFixed(2);
        
        logger.info(`  Inferencia completada en ${inferenceTime}s`);

        // Parse respuesta JSON
        let parsed;
        try {
            parsed = JSON.parse(data.response);
        } catch (e) {
            // Intenta extraer JSON si viene con texto adicional
            const jsonMatch = data.response.match(/\{[\s\S]*\}/);
            if (jsonMatch) {
                parsed = JSON.parse(jsonMatch[0]);
            } else {
                logger.error('Respuesta no es JSON v√°lido:', data.response.substring(0, 200));
                throw new Error('No se pudo parsear respuesta JSON de Ollama');
            }
        }

        // Valida campos requeridos
        const required = [
            'resumen_ejecutivo', 
            'temas_principales', 
            'insights_clave', 
            'relevancia', 
            'categoria', 
            'tipo_contenido'
        ];
        
        for (const field of required) {
            if (!parsed[field]) {
                throw new Error(`Campo requerido faltante en respuesta: ${field}`);
            }
        }

        // Valida tipos
        if (!Array.isArray(parsed.temas_principales) || !Array.isArray(parsed.insights_clave)) {
            throw new Error('temas_principales e insights_clave deben ser arrays');
        }

        if (typeof parsed.relevancia !== 'number' || parsed.relevancia < 1 || parsed.relevancia > 5) {
            throw new Error('relevancia debe ser n√∫mero entre 1 y 5');
        }

        return {
            ...parsed,
            processing_time_seconds: parseFloat(inferenceTime)
        };

    } catch (error) {
        logger.error('‚ùå Error en an√°lisis Ollama:', error.message);
        return null;
    }
}

/**
 * Prueba conexi√≥n con Ollama y valida modelo
 * @returns {Promise<boolean>} True si est√° operativo
 */
async function testOllama() {
    try {
        logger.info('Verificando Ollama...');
        
        const response = await fetch(`${OLLAMA_HOST}/api/tags`);
        
        if (!response.ok) {
            throw new Error(`HTTP ${response.status}: ${response.statusText}`);
        }
        
        const data = await response.json();
        
        if (!data.models || data.models.length === 0) {
            logger.error('‚úó No hay modelos instalados en Ollama');
            logger.error('  Ejecuta: ollama pull llama3.1:8b');
            return false;
        }
        
        const modelExists = data.models.some(m => m.name === OLLAMA_MODEL);
        
        if (!modelExists) {
            logger.error(`‚úó Modelo '${OLLAMA_MODEL}' no encontrado`);
            logger.error('  Modelos disponibles:');
            data.models.forEach(m => {
                logger.error(`    - ${m.name} (${(m.size / 1e9).toFixed(2)} GB)`);
            });
            logger.error(`  Cambia OLLAMA_MODEL en .env o ejecuta: ollama pull ${OLLAMA_MODEL}`);
            return false;
        }
        
        const selectedModel = data.models.find(m => m.name === OLLAMA_MODEL);
        logger.info(`‚úì Ollama operativo`);
        logger.info(`  Modelo: ${OLLAMA_MODEL}`);
        logger.info(`  Tama√±o: ${(selectedModel.size / 1e9).toFixed(2)} GB`);
        logger.info(`  Modificado: ${new Date(selectedModel.modified_at).toLocaleString()}`);
        
        return true;
    } catch (error) {
        logger.error('‚úó Error conectando con Ollama:', error.message);
        logger.error('  Verifica que Ollama est√© ejecut√°ndose: ollama serve');
        return false;
    }
}

module.exports = { analyzeContent, testOllama };
